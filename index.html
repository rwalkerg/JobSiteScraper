<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Job Scraper</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; }
        .loader {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #3498db;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body class="bg-gray-50 text-gray-800">

    <div class="container mx-auto max-w-3xl px-4 py-8 sm:py-12">
        
        <!-- Header -->
        <header class="text-center mb-8">
            <h1 class="text-4xl font-bold text-gray-900 tracking-tight">Job Scraper</h1>
            <p class="mt-2 text-lg text-gray-600">Enter a job search URL and keywords to find relevant listings.</p>
        </header>

        <!-- Main Form -->
        <main class="bg-white p-6 sm:p-8 rounded-2xl shadow-lg">
            <form id="scraper-form">
                <div class="space-y-6">
                    <div>
                        <label for="search-url" class="block text-sm font-medium leading-6 text-gray-900">Job Search URL</label>
                        <div class="mt-2">
                            <input type="url" name="search-url" id="search-url" class="block w-full rounded-md border-0 py-2.5 px-3 text-gray-900 shadow-sm ring-1 ring-inset ring-gray-300 placeholder:text-gray-400 focus:ring-2 focus:ring-inset focus:ring-indigo-600 sm:text-sm sm:leading-6" placeholder="https://www.indeed.com/jobs?q=python+developer" required>
                        </div>
                        <p class="mt-2 text-xs text-gray-500">The URL of the search results page (e.g., Indeed, LinkedIn).</p>
                    </div>

                    <div>
                        <label for="keywords" class="block text-sm font-medium leading-6 text-gray-900">Keywords</label>
                        <div class="mt-2">
                            <input type="text" name="keywords" id="keywords" class="block w-full rounded-md border-0 py-2.5 px-3 text-gray-900 shadow-sm ring-1 ring-inset ring-gray-300 placeholder:text-gray-400 focus:ring-2 focus:ring-inset focus:ring-indigo-600 sm:text-sm sm:leading-6" placeholder="python, django, remote, aws" required>
                        </div>
                        <p class="mt-2 text-xs text-gray-500">Comma-separated keywords to look for in job descriptions.</p>
                    </div>
                </div>

                <div class="mt-8">
                    <button type="submit" id="submit-button" class="flex w-full justify-center items-center rounded-md bg-indigo-600 px-3 py-2.5 text-sm font-semibold leading-6 text-white shadow-sm hover:bg-indigo-500 focus-visible:outline focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-indigo-600 disabled:bg-indigo-300">
                        Start Scraping
                    </button>
                </div>
            </form>
        </main>

        <!-- Status and Results -->
        <section id="results-section" class="mt-8 hidden">
            <div class="bg-white p-6 sm:p-8 rounded-2xl shadow-lg">
                <h2 class="text-2xl font-bold text-gray-900 mb-4">Results</h2>
                
                <!-- Status Message Area -->
                <div id="status-container" class="text-center py-8">
                    <div id="loader" class="loader mx-auto mb-4 hidden"></div>
                    <p id="status-message" class="text-gray-600"></p>
                </div>

                <!-- Results List -->
                <div id="results-list" class="mt-4 space-y-4">
                    <!-- Matched jobs will be injected here by JavaScript -->
                </div>
            </div>
        </section>

    </div>

    <script>
        const scraperForm = document.getElementById('scraper-form');
        const submitButton = document.getElementById('submit-button');
        const resultsSection = document.getElementById('results-section');
        const statusContainer = document.getElementById('status-container');
        const statusMessage = document.getElementById('status-message');
        const loader = document.getElementById('loader');
        const resultsList = document.getElementById('results-list');

        scraperForm.addEventListener('submit', async (event) => {
            event.preventDefault(); // Prevent the form from submitting the traditional way

            // --- UI Setup ---
            submitButton.disabled = true;
            submitButton.textContent = 'Scraping...';
            resultsSection.classList.remove('hidden');
            resultsList.innerHTML = ''; // Clear previous results
            statusMessage.textContent = 'Scraping job site... this may take up to 25 seconds.';
            loader.classList.remove('hidden');

            // --- Get Form Data ---
            const searchUrl = document.getElementById('search-url').value;
            const keywordsInput = document.getElementById('keywords').value;
            // Split keywords by comma and trim whitespace
            const keywords = keywordsInput.split(',').map(k => k.trim().toLowerCase()).filter(k => k);

            try {
                // --- API Call to Netlify Function ---
                const response = await fetch('/.netlify/functions/scrape', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        search_url: searchUrl,
                        keywords: keywords,
                    }),
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.error || `HTTP error! Status: ${response.status}`);
                }

                const data = await response.json();
                
                // --- Display Results ---
                loader.classList.add('hidden');
                if (data.matched_jobs && data.matched_jobs.length > 0) {
                    statusMessage.textContent = `Success! Found ${data.matched_jobs.length} matching jobs.`;
                    data.matched_jobs.forEach(job => {
                        const jobElement = document.createElement('div');
                        jobElement.className = 'p-4 border rounded-lg bg-gray-50';
                        jobElement.innerHTML = `
                            <a href="${job.link}" target="_blank" rel="noopener noreferrer" class="text-indigo-600 hover:text-indigo-800 font-medium break-all">${job.title || job.link}</a>
                            <p class="text-sm text-gray-500 mt-1">Keywords found: ${job.found_keywords.join(', ')}</p>
                        `;
                        resultsList.appendChild(jobElement);
                    });
                } else {
                    statusMessage.textContent = 'Scraping complete. No jobs found matching your keywords.';
                }

            } catch (error) {
                // --- Display Errors ---
                console.error('Scraping error:', error);
                loader.classList.add('hidden');
                statusMessage.textContent = `Error: ${error.message}`;
                statusMessage.classList.add('text-red-600');
            } finally {
                // --- Reset UI ---
                submitButton.disabled = false;
                submitButton.textContent = 'Start Scraping';
            }
        });
    </script>
</body>
</html>
```python
# netlify/functions/scrape.py

import json
import requests
from bs4 import BeautifulSoup
import time

# --- IMPORTANT: You may need to adjust these selectors for different job sites ---
# These are examples for Indeed.com
LINK_SELECTOR = 'a.jcs-JobTitle'
DESCRIPTION_SELECTOR = 'div#jobDescriptionText'
BASE_URL = "[https://www.indeed.com](https://www.indeed.com)" # Used to construct full URLs if links are relative
# ---

# User agent to mimic a real browser
USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'

def get_job_links(url):
    """Fetches the main search page and extracts all job links."""
    headers = {'User-Agent': USER_AGENT}
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        link_elements = soup.select(LINK_SELECTOR)
        
        # Handle both relative and absolute links
        job_links = []
        for link in link_elements:
            href = link.get('href')
            if href:
                if href.startswith('/'):
                    job_links.append(BASE_URL + href)
                else:
                    job_links.append(href)
        
        return list(set(job_links)) # Return unique links
    except requests.exceptions.RequestException as e:
        print(f"Error fetching main page {url}: {e}")
        raise ValueError(f"Could not fetch the job search URL. Please check the link. Error: {e}")


def check_page_for_keywords(url, keywords):
    """Visits a single job page and checks which keywords are present."""
    headers = {'User-Agent': USER_AGENT}
    try:
        # Add a small delay to be respectful to the server
        time.sleep(0.5)
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        description_div = soup.select_one(DESCRIPTION_SELECTOR)
        if not description_div:
            return None, [] # Return if no description found

        page_text = description_div.get_text().lower()
        
        found_keywords = [kw for kw in keywords if kw in page_text]
        
        # Extract job title if possible
        title = soup.title.string if soup.title else url

        if found_keywords:
            return {'title': title, 'link': url, 'found_keywords': found_keywords}, found_keywords
        return None, []
        
    except Exception as e:
        print(f"Could not check page {url}. Reason: {e}")
        return None, []


def handler(event, context):
    """
    Netlify Function handler. Receives a URL and keywords, scrapes the site,
    and returns a list of matched jobs.
    """
    try:
        # --- 1. Get data from the frontend ---
        body = json.loads(event.get('body', '{}'))
        search_url = body.get('search_url')
        keywords = body.get('keywords', [])

        if not search_url or not keywords:
            return {
                'statusCode': 400,
                'body': json.dumps({'error': 'Missing search_url or keywords.'})
            }

        # --- 2. Scrape the main page for links ---
        # Netlify functions have a timeout (around 10-26s). We limit the number of links to process.
        all_links = get_job_links(search_url)
        links_to_process = all_links[:15] # Process a maximum of 15 links to avoid timeouts
        print(f"Found {len(all_links)} links, processing the first {len(links_to_process)}.")

        # --- 3. Visit each page and check for keywords ---
        matched_jobs = []
        for link in links_to_process:
            job_details, _ = check_page_for_keywords(link, keywords)
            if job_details:
                matched_jobs.append(job_details)
        
        print(f"Found {len(matched_jobs)} matching jobs.")

        # --- 4. Return the results to the frontend ---
        return {
            'statusCode': 200,
            'headers': {'Content-Type': 'application/json'},
            'body': json.dumps({'matched_jobs': matched_jobs})
        }

    except ValueError as ve:
        # Handle specific, user-facing errors
        return {
            'statusCode': 400,
            'body': json.dumps({'error': str(ve)})
        }
    except Exception as e:
        # Handle unexpected server errors
        print(f"An unexpected error occurred: {e}")
        return {
            'statusCode': 500,
            'body': json.dumps({'error': 'An internal server error occurred.'})
        }

```toml
# netlify.toml

# This configuration is for a web app with a backend function.
# The schedules from the previous version are no longer needed.

[build]
  # This tells Netlify where to find your site's files.
  # Since index.html is in the root, we can set it to the root.
  publish = "." 

[functions]
  # This tells Netlify where to find your function files.
  directory = "netlify/functions/"
